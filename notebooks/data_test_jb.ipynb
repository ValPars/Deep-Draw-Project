{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data - BitMap in numpy \n",
    "Choosing 10 categories from QuickDraw dataset :\n",
    "    - cat\n",
    "    - bear\n",
    "    - car\n",
    "    - eye\n",
    "    - hat\n",
    "    - frog\n",
    "    - crown\n",
    "    - guitar\n",
    "    - pig\n",
    "    - coffee cup\n",
    "100K image per elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 11:10:37.959002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root, test_size=0.2, max_items_per_class= 1000):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    X = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load a subset of the data to memory \n",
    "    for idx, file in enumerate(all_files):\n",
    "        print(file,\"loaded\")\n",
    "        data = np.load(file)\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        X = np.concatenate((X, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "\n",
    "    #shuffle (to be sure)\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    X = X[permutation, :]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    #separate into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_npy/full_numpy_bitmap_hat.npy loaded\n",
      "data_npy/full_numpy_bitmap_cat.npy loaded\n",
      "data_npy/full_numpy_bitmap_eye.npy loaded\n",
      "data_npy/full_numpy_bitmap_car.npy loaded\n",
      "data_npy/full_numpy_bitmap_guitar.npy loaded\n",
      "data_npy/full_numpy_bitmap_frog.npy loaded\n",
      "data_npy/full_numpy_bitmap_coffee cup.npy loaded\n",
      "data_npy/full_numpy_bitmap_crown.npy loaded\n",
      "data_npy/full_numpy_bitmap_bear.npy loaded\n",
      "data_npy/full_numpy_bitmap_pig.npy loaded\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, class_names = load_data(\"data_npy\", test_size=0.2, max_items_per_class= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_numpy_bitmap_hat',\n",
       " 'full_numpy_bitmap_cat',\n",
       " 'full_numpy_bitmap_eye',\n",
       " 'full_numpy_bitmap_car',\n",
       " 'full_numpy_bitmap_guitar',\n",
       " 'full_numpy_bitmap_frog',\n",
       " 'full_numpy_bitmap_coffee cup',\n",
       " 'full_numpy_bitmap_crown',\n",
       " 'full_numpy_bitmap_bear',\n",
       " 'full_numpy_bitmap_pig']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "image_size=28\n",
    "num_classes = len(class_names)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices, one hot encoded\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6700, 28, 28, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               73856     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,442\n",
      "Trainable params: 98,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax')) \n",
    "# Train model\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "210/210 [==============================] - 5s 21ms/step - loss: 1.4630 - accuracy: 0.5012\n",
      "Epoch 2/10\n",
      "210/210 [==============================] - 4s 20ms/step - loss: 0.9154 - accuracy: 0.6996\n",
      "Epoch 3/10\n",
      "210/210 [==============================] - 4s 20ms/step - loss: 0.7365 - accuracy: 0.7573\n",
      "Epoch 4/10\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 0.6251 - accuracy: 0.7916\n",
      "Epoch 5/10\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 0.5512 - accuracy: 0.8151\n",
      "Epoch 6/10\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 0.4713 - accuracy: 0.8452\n",
      "Epoch 7/10\n",
      "210/210 [==============================] - 4s 20ms/step - loss: 0.4133 - accuracy: 0.8613\n",
      "Epoch 8/10\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 0.3480 - accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "210/210 [==============================] - 5s 23ms/step - loss: 0.2875 - accuracy: 0.9007\n",
      "Epoch 10/10\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 0.2381 - accuracy: 0.9176\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 32, epochs= 10, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "\n",
    "    with plt.style.context('seaborn-deep'):\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "        ## Plot Losses and Accuracies\n",
    "        x_axis = np.arange(len(history.history['loss']))\n",
    "\n",
    "        ax[0].set_title(\"Loss\")\n",
    "        ax[0].plot(x_axis, history.history['loss'], color=\"blue\", linestyle=\":\", marker=\"X\", label=\"Train Loss\")\n",
    "        ax[0].plot(x_axis, history.history['val_loss'], color=\"orange\", linestyle=\"-\", marker=\"X\", label=\"Val Loss\")\n",
    "\n",
    "        ax[1].set_title(\"Accuracy\")\n",
    "        ax[1].plot(x_axis, history.history['accuracy'], color=\"blue\", linestyle=\":\", marker=\"X\", label=\"Train Accuracy\")\n",
    "        ax[1].plot(x_axis,\n",
    "                   history.history['val_accuracy'],\n",
    "                   color=\"orange\",\n",
    "                   linestyle=\"-\",\n",
    "                   marker=\"X\",\n",
    "                   label=\"Val Accuracy\")\n",
    "\n",
    "        ## Customization\n",
    "        ax[0].grid(axis=\"x\", linewidth=0.5)\n",
    "        ax[0].grid(axis=\"y\", linewidth=0.5)\n",
    "        ax[0].legend()\n",
    "        ax[1].grid(axis=\"x\", linewidth=0.5)\n",
    "        ax[1].grid(axis=\"y\", linewidth=0.5)\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_loss_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m, in \u001b[0;36mplot_loss_accuracy\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     10\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(x_axis, history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(x_axis, \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ax[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m ax[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(x_axis, history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(dataset)\n\u001b[1;32m      3\u001b[0m max_item_per_cl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m\n\u001b[1;32m      4\u001b[0m class_name \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = \"data_npy\"\n",
    "files = os.listdir(dataset)\n",
    "max_item_per_cl = 1500\n",
    "class_name = []\n",
    "\n",
    "size = 0\n",
    "\n",
    "for name in files :\n",
    "    #Evaluate the size of the dataset\n",
    "    \n",
    "    data= np.load(os.path.join(dataset, name))\n",
    "    data= data[:max_item_per_cl]\n",
    "    size += data.shape[0]\n",
    "\n",
    "\n",
    "#create 2 buffers to stock data\n",
    "X = np.zeros((size, 28, 28)) #images\n",
    "y = np.zeros((size,)) #targets\n",
    "\n",
    "\n",
    "i=0\n",
    "t=0\n",
    "for name in files :\n",
    "    #open each dataset and add a new class\n",
    "    class_name.append(name.replace(\"full_numpy_bitmap_\", \"\").replace(\".npy\", \"\"))\n",
    "    data= np.load(os.path.join(dataset, name))\n",
    "    data= data[:max_item_per_cl]\n",
    "    #add image to the buffers\n",
    "    X[i:i + data.shape[0]] = np.invert(data.reshape(-1, 28, 28))\n",
    "    y[i:i + data.shape[0]] = t\n",
    "    #iterate\n",
    "    i += data.shape[0]\n",
    "    t += 1\n",
    "\n",
    "#Shuffle dataset\n",
    "idx = np.arange(size)\n",
    "np.random.shuffle(idx)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size= 0.33)\n",
    "\n",
    "print(\"X.shape\", X.shape)\n",
    "print(\"y.shape\", y.shape)\n",
    "\n",
    "print(\"X_val.shape\", X_val.shape)\n",
    "print(\"y.shape\", y_val.shape)\n",
    "\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization (avoid scale effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std 209.52174370494467 85.21704864839893\n"
     ]
    }
   ],
   "source": [
    "print(\"mean and std\", X.mean(), X.std())\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(-1, 28*28))\n",
    "X_val_scaled = scaler.fit_transform(X_val.reshape(-1, 28*28))\n",
    "\n",
    "X_scaled = X_scaled.reshape(-1, 28, 28, 1)\n",
    "X_val_scaled = X_val_scaled.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset (object tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(X_scaled)\n",
    "val_data = tf.data.Dataset.from_tensor_slices(X_val_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### biblio\n",
    "\n",
    "Challenges & lectures\n",
    "\n",
    "--> data-intuition-on-convolutions\n",
    "--> data-cifar-classification\n",
    "--> data-transfer-learning\n",
    "--> data-autoencoder\n",
    "—-> data-recap_cnn\n",
    "\n",
    "docs\n",
    "\n",
    "--> https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "--> https://www.youtube.com/watch?v=rsMVCPIq8iY --> loading data\n",
    "--> https://www.youtube.com/watch?v=sdIINp0-CAA --> tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "34d2c4ff737901f53b6ef05e50e8cbe771936318a89318001668b198400b205a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
